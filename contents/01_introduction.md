
# Herausforderungen bei der Akzeptanztesterstellung {#sec:challenges}

Akzeptanztests dienen im Softwareentwicklungsprozess dazu sicherzustellen, dass die umgesetzte Lösung die fachlichen Anforderungen wie gewünscht abdecken. Sie stellen damit einen essentiellen Baustein zur Qualitätssicherung und Projektsteuerung dar. Besonders wertvoll sind Akzeptanztests dann, wenn sie, im Sinne des "Test-First-Prinzips" direkt mit den Anforderungen zusammen spezifiziert werden, und somit während der Entwicklung bereits zur Verfügung stehen. In agilen Entwicklungsprozessen komplementieren Akzeptanztests die User-Stories und stellen sicher, dass die formulierten Akzeptanzkriterien überprüfbar sind. Automatisch ausführbare Akzeptanztests können bereits während der Entwicklung als Richtschnur und Fortschrittskontrolle dienen, um Iterationen zur Nachbesserung zu reduzieren und Resourcen möglichst optimal zu verteilen.

Für die Erstellung von Akzeptanztests ergibt sich allerdings häufig ein Dilemma: Auf der einen Seite verfügen nur die Anwender über das jeweilige domänenspezifische Fachwissen, um die Tests entsprechend der Anforderungen zu formulieren. Auf der anderen Seite werden zur Automatisierung der Tests aber Programmierkenntnisse benötigt, so dass diese Aufgabe den Software-Entwicklern zufällt. Wird die Testautomatisierung aber von Entwicklern vorgenommen, birgt dies die Gefahr, dass sich bei der Implementierung von Testspezifikationen, etwa durch mißverständliche Formulierungen in den Testspezifikationen oder unzureichendes Verständnis der Fachdomäne, Fehler einschleichen. In der Praxis wird stattdessen auf die Automatisierung ganz oder teilweise verzichtet. Die manuelle Durchführung von Akzeptanztests ist fehleranfällig, nicht zuverlässig wiederholbar und um ein vielfaches aufwändiger, so dass sie nicht prozessbegleitend eingesetzt werden kann. Insgesamt beraubt es den Entwicklungsprozess also an Agilität, da manuelles Testen für iterativ-inkrementelle Entwicklung ungeeignet ist. Schlimmstenfalls werden Akzeptanztests als so aufwändig eingeschätzt, dass gänzlich auf sie verzichtet wird. Eine solche Lücke in der Qualitätssicherung führt zu einem entsprechend erhöhten Risiko von Fehlern im Produktivsystem und hohen Kosten für Nachbesserungen und Wartung.

Kern des Problems ist, dass in der Akzeptanztesterstellung die Belange von Fachanwendern und Entwicklern nicht entlang ihrer jeweiligen Kenntnisse und Fähigkeiten getrennt wird. Bekannte Werkzeuge am Markt, wie etwa [Cucumber](https://cucumber.io/) oder [Gauge](https://gauge.org/), stellen im Wesentlichen die Nachverfolgbarkeit zwischen Testspezifikationen und ausführbaren Testfällen her. Erstere werden durch Fachanwender in natürlicher Sprache verfasst, letztere werden durch Entwickler unter Bezug auf die jeweiligen Spezifikationen implementiert. Um der geschilderten Problematik zu begegnen muss das Ziel aber sein, die Fachanwender selbst in die Lage zu versetzen, automatisch ausführbare Tests zu beschreiben. Da diese in der Regel nicht über Programmierkenntnisse verfügen, muss ein geeignetes Werkzeug Konzepte zur Testbeschreibung anbieten, die entweder allgemeinverständlich sind, sich also z.B. an natürlicher Sprache orientieren, oder sich aus dem fachspezifischen Vokabular der Anwendungsdomäne ableiten. Einen solchen Ansatz verfolgt der Test-Editor.